spring.application.name=LocalSpringAI
server.port=9090


#openAPI key
#spring.ai.openai.api-key=s{yourAPI KEY}
#spring.ai.openai.enabled=false

#ollama
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.model=mistral:7b
spring.ai.ollama.chat.options.model=mistral:7b
#ollama.base-url=http://localhost:11434

#docker and ollama locally url for stream response
ollama.base-url=http://host.docker.internal:11434
ollama.api-path=/api/chat
ollama.model=mistral:7b
